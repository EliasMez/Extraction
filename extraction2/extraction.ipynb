{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb58223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import finditer, search, match\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbbf2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileCA = open(\"source/sample-ca.txt\", \"r\")\n",
    "fileUSA = open(\"source/united_states_profiles.txt\", \"r\")\n",
    "fileSI = open(\"source/singapore_profiles.txt\", \"r\")\n",
    "fileIL = open(\"source/sample-il.txt\", \"r\")\n",
    "lines = fileUSA.readlines() + fileSI.readlines() + fileCA.readlines() + fileIL.readlines()\n",
    "fileCA.close()\n",
    "fileUSA.close()\n",
    "fileSI.close()\n",
    "fileIL.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf544f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_val = \":.+\"\n",
    "reg = \"\\\"[^:,]+\\\": (((\\[\\]|\\[.*?(}|\\\")\\])(,|}))|((\\\"\\\")|(\\\".+?\\\"),)|.*?,)\"\n",
    "\n",
    "columns = [i.group().split(':')[0].strip('\"') for i in finditer(reg,lines[0])]\n",
    "valeurs = [[search(reg_val,i.group()).group().strip(': \",}') for i in finditer(reg,line)] for line in lines]\n",
    "\n",
    "df = pd.DataFrame(valeurs, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4d56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_columns = ['public_identifier',\n",
    " 'profile_pic_url',\n",
    " 'background_cover_image_url',\n",
    " 'first_name',\n",
    " 'last_name',\n",
    " 'full_name',\n",
    " 'occupation',\n",
    " 'headline',\n",
    " 'summary',\n",
    " 'country',\n",
    " 'country_full_name',\n",
    " 'city',\n",
    " 'state',\n",
    " 'connections']\n",
    "\n",
    "df_profils = df[atom_columns]\n",
    "df_profils.to_csv('destination/profils.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d02151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_col = '[^:,]+\": ({.+?},|(\".+?[^\\\\\\]\")|.*?(,|}))'\n",
    "reg_date = \"[0-9]{1,4}\"\n",
    "reg_sep = \"{([^{}]*{[^{}]*}[^{}]*)*}|{.+?}\"\n",
    "\n",
    "rep_col = lambda s : s.strip('{').strip(' ').strip('\"') \n",
    "sep = lambda column,i_line : [unique.group() for unique in finditer(reg_sep,df[column][i_line])]\n",
    "pref_col = lambda column : ['public_identifier','num_'+column]\n",
    "sub = lambda column,i_line :  pref_col(column) + [rep_col(i.group().split(': ')[0]) for i in finditer(reg_col,sep(column,i_line)[0])]\n",
    "profil = lambda i_line : df['public_identifier'][i_line]\n",
    "\n",
    "def sub_cols(column):\n",
    "    test_line = 0\n",
    "    while (sep(column,test_line) == []) :\n",
    "        test_line +=1\n",
    "    return sub(column,test_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73b020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_val = lambda column,i_line,i_col : [profil(i_line), i_col+1]+['-'.join([date.group().zfill(2) for date in finditer(reg_date, search(reg_val,val.group()).group().strip(': \",'))]) if '{' in val.group() else (search(reg_val,val.group()).group().strip(': \",}')) for val in finditer(reg_col,sep(column,i_line)[i_col])]\n",
    "sub_vals = lambda column : [sub_val(column,i_line,i_col) for i_line in range(len(lines)) for i_col in range(len(sep(column,i_line)))]\n",
    "\n",
    "non_atom_cols = ['experiences',\n",
    " 'education',\n",
    " #'languages',\n",
    " 'accomplishment_organisations',\n",
    " 'accomplishment_publications',\n",
    " 'accomplishment_honors_awards',\n",
    " 'accomplishment_patents',\n",
    " 'accomplishment_courses',\n",
    " 'accomplishment_projects',\n",
    " 'accomplishment_test_scores',\n",
    " 'volunteer_work',\n",
    " 'certifications',\n",
    " #'people_also_viewed',\n",
    " 'recommendations',\n",
    " 'activities',\n",
    " 'similarly_named_profiles',\n",
    " 'articles',\n",
    " #'groups'\n",
    "                ]\n",
    "\n",
    "dfs = [pd.DataFrame(sub_vals(non_atom_col), columns = sub_cols(non_atom_col)) for non_atom_col in non_atom_cols]\n",
    "[dfs[i_df].to_csv('destination/'+non_atom_cols[i_df]+'.csv', sep=\";\", index=False) for i_df in range(len(non_atom_cols))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30205d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cols_languages = pref_col('languages') + ['language']\n",
    "rep_lang = lambda s : s.strip('][').replace(' ','').replace('\"','').split(',')\n",
    "languages = lambda i_line : rep_lang(df['languages'][i_line])\n",
    "sub_vals_languages = [[profil(i_line),num_language+1,languages(i_line)[num_language]] for i_line in range(len(lines)) for num_language in range(len(languages(i_line))) if languages(i_line) !=['']]\n",
    "\n",
    "df_languages = pd.DataFrame(sub_vals_languages, columns = sub_cols_languages)\n",
    "df_languages.to_csv('destination/languages.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc49384",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_sep_rec = '\".+?\"(,|\\])'\n",
    "sub_cols_recommendations = pref_col('recommendations') + ['recommendation']\n",
    "sep_rec = lambda i_line : [unique.group() for unique in finditer(reg_sep_rec,df['recommendations'][i_line])]\n",
    "rep_rec = lambda s : s.replace('\\\\\"','\"').replace('\",','').replace('\"','').replace('  ','').replace(']','')\n",
    "sub_val_recommendation = lambda i_line,i_col : [profil(i_line),i_col+1,rep_rec(sep_rec(i_line)[i_col])]\n",
    "sub_vals_recommendations = [sub_val_recommendation(i_line,i_col) for i_line in range(len(lines)) for i_col in range(len(sep_rec(i_line)))]\n",
    "\n",
    "df_recommendations = pd.DataFrame(sub_vals_recommendations, columns = sub_cols_recommendations)\n",
    "df_recommendations.to_csv('destination/recommendations.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c649e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_vals_groups = [sub_val('groups',i_line,i_col) for i_line in range(len(lines[:20000])) for i_col in range(len(sep('groups',i_line)))]\n",
    "df_groups = pd.DataFrame(sub_vals_groups, columns = sub_cols('groups'))\n",
    "df_groups.to_csv('destination/groups.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5809083",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_vals_people_also_viewed1 = [sub_val('people_also_viewed',i_line,i_col) for i_line in range(len(lines[:20000])) for i_col in range(len(sep('people_also_viewed',i_line)))]\n",
    "sub_vals_people_also_viewed2 = [sub_val('people_also_viewed',i_line,i_col) for i_line in range(len(lines[20000:])) for i_col in range(len(sep('people_also_viewed',i_line)))]\n",
    "sub_vals_people_also_viewed = sub_vals_people_also_viewed1+sub_vals_people_also_viewed2\n",
    "\n",
    "df_people_also_viewed = pd.DataFrame(sub_vals_people_also_viewed, columns = sub_cols('people_also_viewed'))\n",
    "df_people_also_viewed.to_csv('destination/people_also_viewed.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DEBOGAGE ATOMIQUE \"\"\"\n",
    "#[search(reg_val,i.group()).group().strip(': \",}') for i in finditer(reg,lines[474])][:12]\n",
    "# df['state'].iloc[474]\n",
    "# lines[474]\n",
    "# df['connections'].value_counts()\n",
    "# v=''; df[(df['connections'] == v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2340bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' DEBOGAGE NON ATOMIQUE '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" DEBOGAGE NON ATOMIQUE \"\"\"\n",
    "\n",
    "# sub_vals('accomplishment_honors_awards')\n",
    "# sub_cols('accomplishment_honors_awards')\n",
    "# df[['accomplishment_honors_awards', 'public_identifier']].head(15)\n",
    "# df[df['accomplishment_honors_awards']!='[]'].accomplishment_honors_awards\n",
    "# df['accomplishment_honors_awards'][37]\n",
    "# sub_val('accomplishment_honors_awards',37,0)\n",
    "# [unique.group() for unique in finditer(reg_sep,df['accomplishment_honors_awards'][37])]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
